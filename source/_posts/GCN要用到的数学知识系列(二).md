---
title: GCN要用到的数学知识系列(二)
date: 2019-12-15 09:59:49
mathjax: true
categories:
- GCN要用到的数学知识
- 卷积的定义和性质
tags: 
- 离散卷积
- 图形处理中的卷积
- 傅里叶变换
---

## **二、卷积的定义和性质**

> 卷积(Convolution)是一个在信号与系统以及机器学习领域极为常见的一个词，本文将从离散和连续两个角度来讲解卷积的定义与性质，同时结合上一讲的傅里叶变换，我们也证明后续在了解GCN时要用到的相关定理。

<!--more-->

### **离散型卷积**

也许你玩过大型多人在线角色扮演游戏(MMORPG)游戏，这类游戏里往往总和**挂dot**离不开，所谓挂dot就是指释放一个技能，让对方持续掉血，而dot的英文就是Damage over time。那么问题来了，现在如果我们挂dot的技能冷却时间是$1$秒，也就是说我们每隔$1$秒就可以对敌人挂一个dot，这个dot伤害每次命中后持续$5$秒，dot命中后每秒对敌人造成$8$点伤害，并且之后每次再挂dot的伤害是之前的$1/2$，也就是说第二次挂dot命中后就是每秒造成就是$4$点伤害$\cdots$以此类推。那么问题来了，我们现在只通过挂dot，在$ns$内可以对敌人造成多少伤害？

这里我们先从一个简单的例子去考虑，假设我们求$4s$内的情况，时间区间的话考虑到边界条件，我们记其为左闭右开区间，就是$[0,4)$，那么容易知道，我们分别在$0s$，$1s，2s，3s$这四个时刻挂了dot。

$0s$时刻挂的dot持续了$4s$，总计造成了$8+8+8+8 = 32$点伤害

$1s$时刻挂的dot持续了$3s$，总计造成了$4+4+4 = 12$点伤害

$2s$时刻挂的dot持续了$2s$，总计造成了$2+2= 4$点伤害

$3s$时刻挂的dot持续了$1s$，总计造成了$1$点伤害

所以在这$4s$内，我们造成的总伤害是$32+12+4+1= 49$ 点。

那这个问题和我们今天的主角卷积又有什么关系呢？不急，我们慢慢来...

注意到上面问题的解的关键在于时间，我们隐约察觉到$ns$内的总伤害是可以写一个关于$n$的公式出来的。那么我们现在把问题一般化，初始条件下敌方身上无dot，那么第一个dot持续$t$秒可以造成的总伤害记为$g(t)$，那么显然有
$$
g(t) = \begin{cases}
{8t}  & t \in \{ 1,2,3,4,5\}\\ 
40    & t \ge 6, t \in N 
\end{cases}
$$

但是每挂一层dot，这层dot就衰减为上一次的$1/2$，这里记初始衰减为$1$，也就是没衰减，我们可以计算$ts$挂出去的dot应该衰减到了最初的多少，记其为$f(t)$，那么有
$$
\begin{align*}
& f(t)=0.5^t \\
\end{align*}
$$
易知，我们$ts$释放的dot获得的衰减为$f(t)$，这个dot实际作用时间是$n-t$，那么$n-t$秒内的无衰减的总伤害就是$g(n-t)$，那么显然$ts$时候命中的dot在这$n$秒以内造成的伤害是$f(t)g(n-t)$，我们记要求的$ns$内总伤害为$F(n)$，那么易知
$$
F(n) = \sum_{t=0}^{n-1}f(t)g(n-t)
$$
是不是有内味儿了？那现在我们把它推广到连续的情况。

### **连续型卷积**

因为现实生活中很多东西是连续的，不像游戏中的dot可能$1s$才能造成一次伤害。其实信号与系统方面的卷积也是这么个意思。此时$f(t)$就是$t$时刻衰减的程度，也可以称之为信号此刻的强度或者幅值，那么$g(n-t)$就是这个信号作用$n-t$秒内的响应，那么$ns$时刻的输出是什么呢？
$$
F(n) = \int_{0}^{\infty}f(t)g(n-t) \space dt
$$
当然定义域也可以拓展为$(-\infty, \infty)$，这里时间的负无穷可以理解为相对时间。数学中通过用*来描述卷积，也就是记函数$f(t)$与函数$g(t)$的卷积为
$$
f * g = \int_{-\infty}^{\infty} f(t) g(n-t) \space dt
$$
至此，我们已经引入了卷积，那么有好奇的小伙伴也会问了？你讲的这个卷积和机器学习中的卷积是一回事吗？

### **图像处理中的卷积**

因为我们输入的图像是一个张量[^1]，比如$32 \times 32 \times 3 $，其中图片分辨率是$32\times32$，通道数为3，比如$RGB$三个通道。注意到我们之前讲述的离散卷积，它在做的事其实也可以看做是**加权**和**求和**，图像中的卷积往往也是利用了这两个性质，这部分知识是CNN(Convolutional Neural Network)中要用到的，但是我们不在此赘述CNN的细节，只是简单的给出一个例子，让读者能明白一个卷积可以对一个图像做什么事？

一个图像处理中非常有名的卷积，$\pmb{prewitt}$算子，在介绍它之前，我们先引入灰度的概念。一个图像的灰度最简单的求法就是取$RGB$三个通道的平均值，也就是$Gray=(R+G+B)/3$，之后令$R=G=B=$$Gray$即可得到一个$RGB$图像的灰度图，$Gray\in [0,255]$，灰度越大的点越趋近与白色，灰度越小的点约趋近于黑色。这个$prewitt$算子其实是一个二维的张量，所以其可以作用在一个灰度图上。这个算子往往用来做边缘检测，它的形式如下
$$
V=\begin{bmatrix}
-1 &0, &1 \\
-1 &0, &1 \\
-1 &0, &1
\end{bmatrix}
H=\begin{bmatrix}
1 &1 &1 \\
0 &0 &0 \\
-1 &-1&-1
\end{bmatrix}
$$
其中$H$用来检测水平边缘，$V$用来检测竖直边缘。那么它是如何做到边缘检测的呢？首先我们需要知道如何定义边缘。比如只含有白和黑两种颜色的图，这里我懒于画图，直接用矩阵的形式来表示这幅图的灰度图
$$
\begin{bmatrix}
255 &255 &255 &255 &255 &255 &255 &255\\
255 &255 &255 &255 &255 &255 &255 &255\\
255 &255 &0 &0 &0 &0 &255 &255\\
255 &255 &0 &0 &0 &0 &255 &255\\
255 &255 &0 &0 &0 &0 &255 &255\\
255 &255 &0 &0 &0 &0 &255 &255\\
255 &255 &255 &255 &255 &255 &255 &255\\
255 &255 &255 &255 &255 &255 &255 &255
\end{bmatrix}
$$
$Perfect!!!!$这幅图中央为$0$点的点是黑色，周围$255$的点为白色，那么显然边缘产生在255和0之间的那两个矩形。

其实所谓边缘就是**灰度变化大于阈值的点**，如何衡量变化呢？函数中我们知道可以用导数或者梯度，可图像不是连续的，我们不能求导，那该如何做呢？**差分**来近似就可以了！这里$prewitt$算子水平方向用$ f '(x) = f(x + 1) - f(x - 1) $近似计算一阶差分，将其系数提出就得到了$[-1,0,1]$，垂直方向同理。

那么如果我们要在水平和垂直混合检测边缘只需要让$prewitt$算子的两个矩阵像CNN一样分别滑过矩阵，得到每个点的水平和垂直变化情况，分别记为$H(x,y),V(x,y)$，然后计算$\sqrt{H(x,y)^{2} + V(x,y)^{2}}$即可，如果这个值大于阈值，那么它就属于边缘。显然$prewitt$算子是利用像素点的上下、左右相邻点灰度差在边缘达到极值这一现象来检测边缘的

那么其实有心的读者应该考虑到了，**$prewitt$算子和图像卷积可以用来提取边缘特征，那是否有一些卷积核可以用来提取其它特征吗？直觉告诉我们应该是有的，CNN就是基于这一思想，将卷积核作为待训练的参数，进而提取特征的。**

### **卷积在傅里叶变换中的性质**

GCN主要用到的性质就是**卷积的傅里叶变换等于傅里叶变换的乘积**，也就是
$$
\mathcal F[f*g]=\mathcal F[f] \times  \mathcal F[g]
$$
要证明这个定理其实很简单，注意到积分上下限都是无穷，所以可以直接交换积分次序，那么就有
$$
\begin{align*}
\mathcal F[f * g] =& \int_{-\infty}^{\infty} (\int_{-\infty}^{\infty} f(\tau) g(t - \tau) \space
 d \tau) \space e^{-jwt} dt \\
 =& \int_{-\infty}^{\infty} f(\tau) e^{-jw\tau}\space d\tau 
 \int_{-\infty}^{\infty} g(t-\tau) e^{-jw(t-\tau)}\space d(t-\tau) \\
 =& \mathcal F[f] \times \mathcal F[g]
\end{align*}
$$

显然如果将这个推广到离散傅里叶变换中去的话，已知对一个自然基下的列向量做傅里叶变换可以得到它在新的基下的坐标[^2]也就是说
$$
\mathcal x=F[v]= U^Tv
$$
其中$U$是新的基下组成的矩阵，那么两个向量$v,u$的卷积的傅里叶变换就有
$$
\begin{align*}
\mathcal F[v*u]=&\mathcal F[v] \times \mathcal F[u] \\
=& U^Tv \times U^Tu
\end{align*}
$$
这里的乘法其实是哈达马积(Hadamard product)，注意到$U^{T} v$以及$U^{T} u$都是相同维度的列向量，所以这里的乘积实际上也就是对应元素直接相乘。

谢谢阅读~~~如有错误或者疏漏欢迎指正。

[^1]:一维度张量可以看做是向量，二维张量可以看做是矩阵。
[^2]:见我的前一篇文章，[傅里叶变换](http://tsotfsk.top/2019/12/14/GCN要用到的数学知识系列(一)/)